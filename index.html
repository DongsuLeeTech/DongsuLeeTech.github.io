<!DOCTYPE html>
<!-- saved from url=(0019)https://dongsuleetech.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="data/js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('config', 'G-3LQTW4VHRT');
    </script>

    <title>Dongsu Lee</title>

    <meta name="author" content="Dongsu Lee">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--<base target="_blank">--><base href="." target="_blank">

    <link rel="icon" type="image/png" sizes="32x32" href="images/favicon/Ds.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon/Ds.png">
</head>


<style>
  .toggle-trigger {
    cursor: pointer;
    color: #FFA500;         /* 기본 텍스트 색 */
    text-decoration: none;
  }
  .toggle-trigger:hover {
    color: #72bf6a;         /* 마우스 올렸을 때 색 */
  }
  .toggle-content {
    display: none;
  }
</style>

<script defer>
function toggleAff(el) {
  const content = el.nextElementSibling;
  const isVisible = content.style.display === 'inline';
  content.style.display = isVisible ? 'none' : 'inline';
  el.textContent = isVisible
    ? 'Previous affiliation.'
    : 'Previously,';}

function toggleRes(el) {
  const content = el.nextElementSibling;
  const isVisible = content.style.display === 'inline';
  content.style.display = isVisible ? 'none' : 'inline';
  el.textContent = isVisible
    ? 'Full research statement.'
    : 'More specifically,';
}

function toggleCore(el) {
  const content = el.nextElementSibling;
  const isVisible = content.style.display === 'inline';
  content.style.display = isVisible ? 'none' : 'inline';
  el.textContent = isVisible
    ? 'My guiding ethos.'
    : 'Hide my guiding ethos.';
}


</script>

<body data-new-gr-c-s-check-loaded="14.1220.0" data-gr-ext-installed="">
<table style="max-width: 800px;">
    <tbody>
    <tr style="padding: 0px;">
        <td style="padding: 0px;">
            <table>
                <tbody>
                <tr style="padding: 0px;">
                    <td style="padding: 20px; width: 75%; vertical-align: middle;">
                        <p style="margin-bottom: 0px; text-align: center;">
                            <span class="text-name">Dongsu Lee</span>
                            <p>
                              Hello! I am a PhD student at the University of Texas at Austin,
                              where I'm supervised by Prof. Amy Zhang in the
                              <a href="https://midi-lab.github.io/publications.html">MIDI Lab</a>.
                                <span class="toggle-trigger"
                                onclick="toggleAff(this)">
                                Previous affiliation.
                                </span>
                                <span class="toggle-content">
                                  I collaborated with Prof. Ding Zhao in the
                                  <a href="https://safeai-lab.github.io/">Safe AI Lab</a>,
                                  Carnegie Mellon University (CMU); with Prof. Minhae Kwon in the
                                  <a href="https://brainmil.wordpress.com/">BMIL</a>; and Prof. Sangsoo Kim in the
                                  <a href="https://sites.google.com/site/sskimb/">Post-genome Informatics Lab</a> at Soongsil University in Seoul, South Korea.
                                </span>
                            </p>

                        <p> The research question I focus on is simple these days: <b>Will reinforcement learning (RL) methods be applicable for practical deployment in realistic settings?</b><br>
                                <span class="toggle-trigger"
                                onclick="toggleRes(this)">
                                Full research statement.
                                </span></p>
                                <div class="toggle-content">
                                <p> I’m interested in real-world challenges, for example, partial observability, coordination with unseen partners, and human-robot collaboration.
                                Then, I aim to make an RL algorithm applicable in <em>multi-agent, open-ended, and robotics settings</em> via both self-play and data-driven techniques.
                                So, I work on multi-agent RL, representation learning, and offline-online RL.</p>

                                <p><b>Test-time coordination with unseen agents</b>: <em>Can RL agents effectively coordinate with partners they've never encountered before?</em><br>
                                Real-world applications frequently require agents to cooperate instantly with unfamiliar teammates. This coordination is challenging, especially when agents operate under partial observability and uncertainty about others' intentions. <br>
                                Inspired by human cognition, I enable RL agents to predict future actions of unseen teammates by inferring their internal preferences from their observed behaviors (NeurIPS 2024). Recently, I have focused more on developing the generalization for zero-shot coordination. <br>
                                Open challenge is: How can agents scale this inference capability efficiently to very large teams or continuously evolving environments?</p>

                                <p><b>Communication multi-agent RL</b>: <em>How can agents communicate efficiently under real-world constraints such as limited bandwidth or noisy environments?</em><br>
                                For teams of robots or virtual agents to succeed, communication is essential—yet it comes at a cost in the real world. Bandwidth constraints, noisy environments, and adversarial disruptions demand smarter, more efficient communication protocols. Ideally, agents should adaptively choose what information to share, with whom, and when, while minimizing the cost and complexity of messages.<br>
                                To address these challenges, I have developed methods that optimize communication among agents via (1) vector quantization and (2) implicit communication (under submission). Through these methods, we allow agents to decide communication links and encode information under realistic limitations; allow coordination without explicit communication at deployment.<br>
                                Open Challenge is: How can we further refine communication protocol to ensure reliable interaction between AI agents and humans, particularly when they have limited prior knowledge of each other's goals or capabilities?</p>

                                <p><b>Efficient representation for RL</b>:

                                    </p>
                                </div>
                        <p>
                            <span class="toggle-trigger"
                                onclick="toggleCore(this)">
                                My guiding ethos.
                                </span>
                                <span class="toggle-content">
                                    <em>Speak truth, amid echoing scorn.<br>
                                    Embrace adventure, born of conviction.<br>
                                    Take responsibility, without retreat.</em>
                                </span>
                        </p>
                <p style="margin-bottom: 0px; text-align: center;">
                  <a href="mailto:dongsu.lee@utexas.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV/DongsuLee-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=v0hNlSUAAAAJ&hl=en&authuser=1">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/dongsulee/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/DongsuLeeTech">Github</a>
                </p>
              </td>
                    <td style="padding: 20px 20px 20px 0px; width: 25%;">
                <a href="images/profile/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
            </tbody>
          </table>

        <table>
            <tbody>
            <tr>
                <td style="padding-bottom: 20px;" class="heading">
                    <span class="text-heading">Selected Publications</span><br>
                </td>
            </tr>
            </tbody>
        </table>

        <table>
            <tbody>
                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Scenario-free Autonomous Driving with Multi-task Offline-to-online Reinforcement Learning</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">IEEE Transactions on Intelligent Transportation Systems</span>
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/11080103">paper</a> |
                            <a href="https://github.com/DongsuLeeTech/O3RL.git">code</a>
<!--                            <a href="https://youtu.be/ocdnWtSJ0yM?feature=shared">talk (10min)</a>-->
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference"> ICML 2025</span>
                            <br>
                            <a href="https://arxiv.org/abs/2505.13144">paper</a> |
                            <a href="https://dongsuleetech.github.io/projects/tempdata/">project page</a>
                            <a href="https://icml.cc/virtual/2025/poster/44612">talk (5min)</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Episodic Future Thinking With Offline Reinforcement Learning for Autonomous Driving</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference"> IEEE IoTJ 2025; IEEE ITSC 2023</span>
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/10421808">paper (short)</a> |
                            <a href="https://sites.google.com/view/eft-pomdpieeeitsc2023/">project page</a> |
                            <a href="https://youtu.be/ocdnWtSJ0yM?feature=shared">talk (10min)</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">NeurIPS 2024</span>
                            <br>
                            <a href="https://arxiv.org/abs/2410.17373">paper</a> |
                            <a href="https://dongsuleetech.github.io/projects/eftm/">project page</a> |
                            <a href="https://neurips.cc/virtual/2024/poster/93443">talk (5min)</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://sites.google.com/view/chanineom/home" class="author-link">Chanin Eom</a>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">ICRA 2024</span>
                            <br>
                            <a href="https://arxiv.org/abs/2404.02429">paper</a> |
                            <a href="https://sites.google.com/view/ad4rl/%ED%99%88#h.cekhbwvkngha">project page</a> |
                            <a href="https://www.youtube.com/watch?v=DGoxmBJrNRc">talk (5min)</a> |
                            <a href="https://www.etnews.com/20240313000363">media</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Instant Inverse Modeling of Stochastic Driving Behavior with Deep Reinforcement Learning</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">IEEE T-CE 2024</span>
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/10684807">paper</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">Stability Analysis in Mixed-autonomous Traffic with Deep Reinforcement Learning</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">IEEE T-VT 2023; NeurIPS DeepRL Workshop 2022</span>
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/10684807">paper</a> |
                            <a href="https://www.eiric.or.kr/util/pdsFileDownload.php?db=TB_Webinar&fileName=FN_23062274008111010972953.pdf">slides </a> |
                            <a href="https://www.youtube.com/watch?v=PA3yHFV3gXY&ab_channel=EIRIC%EC%9D%B4%EB%A6%AD">invited talk (korean)</a> |
                            <a href="https://www.dt.co.kr/contents.html?article_no=2022110102109919613004&ref=naver">media</a>
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="pub-contents">
                        <span class="text-papertitle">ADAS-RL: Safety Learning Approach for Stable Autonomous Driving</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>
                            <br>
                            <span class="text-conference">ICT Express 2022</span>
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/10684807">paper</a>
                        </div>
                    </td>
                </tr>

                </tbody>
            </table>
            <table>
                <tbody>
                <tr>
                    <td class="heading">
                        <span class="text-heading">Patents</span>
                    </td>
                </tr>
                </tbody>
            </table>
            <table>
                <tbody>
                <tr>
                    <td class="pub-contents">
                        <span class="text-patenttitle">Method for Combating Stop-and-Go Wave Problem Using Deep Reinforcement Learning based Autonomous Vehicles, Recording medium and device for performing this the method</span>
                        <div class="pub-description">
                            <strong><a href="https://dongsuleetech.github.io/" class="dongsu-link">Dongsu Lee</a></strong>,
                            <a href="https://brainmil.wordpress.com/minhae/" class="author-link">Minhae Kwon</a>,
                            <span class="text-conference">Patent no. US 12,091,025 (Sep 2024)</span>
                        </div>
                    </td>
                </tr>
                </tbody>
            </table>

            <table>
                <tbody>
                <tr>
                    <td class="heading">
                        <span class="text-heading">Honors and Awards</span>
                    </td>
                </tr>
                </tbody>
            </table>
            <table>
                <tbody>
                <tr>
                    <td class="threelevel contents">
                        <h3>Scholarships</h3>
                    </td>
                </tr>
                <tr>
                    <td class="threelevel contents">
                        <p>
                            <strong>AI Intensive Program at Carnegie Mellon University</strong> (Aug 2024 - Feb 2025)
                        </p>
                        <p class="three-inner">
                            IITP & Sogang University
                            (USD 41K)
                        </p>
                    </td>
                </tr>
                <tr>
                    <td class="threelevel contents">
                        <p>
                            <strong>Future Industrial Talent Scholarship</strong> (Aug 2023 - Feb 2025)
                        </p>
                        <p class="three-inner">
                            CMK Hyundai Group
                            (Full tuition + KRW 3,600K / year)
                        </p>
                    </td>
                </tr>
                    <td class="threelevel contents">
                        <h3>Awards</h3>
                    </td>
                </tr>
                <tr>
                    <td class="threelevel-condensed contents">
                        <p><strong>Global Excellence Scholarship</strong> (Prize: KRW 3,000K), CMK Hyundai Group (Mar, Dec, Dec 2024)</p>
                    </td>
                </tr>
                <tr>
                    <td class="threelevel-condensed contents">
                        <p><strong>ICT Challenge IITP President’s Award</strong> (Prize: KRW 5,000K), IITP (Sep 2023)</p>
                    </td>
                </tr>
                </tbody>
            </table>

            <table>
                <tbody>
                <tr>
                    <td class="heading">
                        <span class="text-heading">Services</span>
                    </td>
                </tr>
                </tbody>
            </table>
            <table>
                <tbody>
                <tr>
                    <td class="threelevel contents">
                        <h3>Reviews</h3>
                    </td>
                </tr>
                <tr>
                    <td class="threelevel-condensed contents">
                        <p>
                            <strong>Journals</strong>:
                            Nature Communication (2025),
                            IEEE T-ITS (2025),
                            IEEE T-CE (2025),
                            IEEE T-VT (2023),
                            IEEE IoT-J (2023)
                        </p>
                        <p>
                            <strong>Conferences</strong>:
                            NeurIPS (2025),
                            CoRL (2025),
                            IRoS (2025),
                            ICRA (2025),
                            ICML (2022)
                        </p>
                        <p>
                            <strong>Workshops</strong>:
                            ICML Theory of Mind Workshop (2023; Program committee),
                            NeurIPS ML4AD (2022)
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

          </tbody></table>
            <table>
                <tbody>
                <tr>
                    <td style="padding: 0px;">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://github.com/jonbarron/website">Template</a>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</tbody></table>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>
